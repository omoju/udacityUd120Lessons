{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 2  - Support Vector Machines\n",
    "\n",
    "This is the code to accompany the Lesson 2 (SVM) mini-project.\n",
    "\n",
    "Use a SVM to identify emails from the Enron corpus by their authors:    \n",
    "1. Sara has label 0\n",
    "2. Chris has label 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omojumiller/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"../tools/\")\n",
    "from email_preprocess import preprocess\n",
    "from prep_terrain_data import makeTerrainData\n",
    "from class_vis import prettyPicture, output_image\n",
    "\n",
    "\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features_train and features_test are the features for the training and testing datasets respectively \n",
    "\n",
    "labels_train and labels_test are the corresponding item labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n"
     ]
    }
   ],
   "source": [
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "#features_train, labels_train, features_test, labels_test = makeTerrainData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 208.973 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel=\"rbf\", gamma=1.0, C = 2)\n",
    "\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "print \"training time:\", round(time()-t0, 3), \"s\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now use a linear classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 0.11 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel=\"linear\")\n",
    "\n",
    "\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "print \"training time:\", round(time()-t0, 3), \"s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeding up the algorithm\n",
    "\n",
    "One way to speed up an algorithm is to train it on a smaller training dataset. The tradeoff is that the accuracy almost always goes down when you do this. Let’s explore this more concretely: add in the following two lines immediately before training your classifier. \n",
    "```python\n",
    "features_train = features_train[:len(features_train)/100] \n",
    "labels_train = labels_train[:len(labels_train)/100] \n",
    "```\n",
    "\n",
    "These lines effectively slice the training dataset down to 1% of its original size, tossing out 99% of the training data. You can leave all other code unchanged. **What’s the accuracy now?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 0.107 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel=\"linear\")\n",
    "\n",
    "features_train = features_train[:len(features_train)/100] \n",
    "labels_train = labels_train[:len(labels_train)/100]\n",
    "\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "print \"training time:\", round(time()-t0, 3), \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing time: 1.107 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "pred = clf.predict(features_test)\n",
    "print \"testing time:\", round(time()-t0, 3), \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def submitAccuracy():\n",
    "    return accuracy_score(pred, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88452787258248011"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submitAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use different kernel\n",
    "Keep the training set slice code from the last quiz, so that you are still training on only 1% of the full training set. Change the kernel of your SVM to “rbf”. \n",
    "**What’s the accuracy now, with this more complex kernel?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 0.115 s\n",
      "testing time: 1.312 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.61604095563139927"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel=\"rbf\")\n",
    "\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "print \"training time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "t0 = time()\n",
    "pred = clf.predict(features_test)\n",
    "print \"testing time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "submitAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune parameters for better accuracy\n",
    "Keep the training set size and rbf kernel from the last quiz, but try several values of C (say, 10.0, 100., 1000., and 10000.). **Which one gives the best accuracy?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 0.112 s\n",
      "testing time: 0.973 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.89249146757679176"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel=\"rbf\", C = 10000)\n",
    "\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "print \"training time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "t0 = time()\n",
    "pred = clf.predict(features_test)\n",
    "print \"testing time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "submitAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized SVM\n",
    "With ```C = 1000``` I got an accuracy of 0.821. With ```C = 10k```, accuracy went up to 0.89\n",
    "\n",
    "Now that you’ve optimized C for the RBF kernel, go back to using the full training set. In general, having a larger training set will improve the performance of your algorithm, so (by tuning C and training on a large dataset) we should get a fairly optimized result. **What is the accuracy of the optimized SVM?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n",
      "training time: 120.323 s\n",
      "testing time: 11.709 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99089874857792948"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train, features_test, labels_train, labels_test = preprocess() # full training set\n",
    "\n",
    "clf2 = svm.SVC(kernel=\"rbf\", C = 10000)\n",
    "\n",
    "t0 = time()\n",
    "clf2.fit(features_train, labels_train)\n",
    "print \"training time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "t0 = time()\n",
    "pred = clf2.predict(features_test)\n",
    "print \"testing time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "submitAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What class does your SVM (0 or 1, corresponding to Sara and Chris respectively) predict for element 10 of the test set? The 26th? The 50th? \n",
    "(Use the RBF kernel, C=10000, and 1% of the training set. Normally you'd get the best results using the full training set, but we found that using 1% sped up the computation considerably and did not change our results--so feel free to use that shortcut here.)\n",
    "\n",
    "And just to be clear, the data point numbers that we give here (10, 26, 50) assume a zero-indexed list. So the correct answer for element #100 would be found using something like answer=predictions[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 0.102 s\n",
      "testing time: 1.21 s\n",
      "class for element 10 is  1\n",
      "class for element 26 is  0\n",
      "class for element 50 is  1\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel=\"linear\")\n",
    "\n",
    "features_train = features_train[:len(features_train)/100] \n",
    "labels_train = labels_train[:len(labels_train)/100]\n",
    "\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "print \"training time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "t0 = time()\n",
    "pred = clf.predict(features_test)\n",
    "print \"testing time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "print \"class for element 10 is \", pred[10]\n",
    "print \"class for element 26 is \", pred[26]\n",
    "print \"class for element 50 is \", pred[50]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are over 1700 test events--how many are predicted to be in the “Chris” (1) class?\n",
    "(Use the RBF kernel, C=10000., and the full training set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of emails that are predicted to be authored by “Chris” (1) class is:  0\n"
     ]
    }
   ],
   "source": [
    "pred = clf2.predict(features_test)\n",
    "len(pred)\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of emails that are predicted to be authored by “Chris” (1) class is:  877\n"
     ]
    }
   ],
   "source": [
    "chrisPred = 0\n",
    "for item in range(len(pred)):\n",
    "    if pred[item] == 1:\n",
    "        chrisPred += 1\n",
    "    \n",
    "print \"The number of emails that are predicted to be authored by “Chris” (1) class is: \", chrisPred\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully it’s becoming clearer what Sebastian meant when he said Naive Bayes is great for text--it’s faster and generally gives better performance than an SVM for this particular problem. Of course, there are plenty of other problems where an SVM might work better. Knowing which one to try when you’re tackling a problem for the first time is part of the art and science of machine learning. In addition to picking your algorithm, depending on which one you try, there are parameter tunes to worry about as well, and the possibility of overfitting (especially if you don’t have lots of training data).\n",
    "\n",
    "Our general suggestion is to try a few different algorithms for each problem. Tuning the parameters can be a lot of work, but just sit tight for now--toward the end of the class we will introduce you to GridCV, a great sklearn tool that can find an optimal parameter tune almost automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### draw the decision boundary with the text points overlaid\n",
    "# This only works for driving dataset. Skip it for the email data set.\n",
    "# prettyPicture(clf, features_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV in sklearn\n",
    "\n",
    "GridSearchCV is a way of systematically working through multiple combinations of parameter tunes, cross-validating as it goes to determine which tune gives the best performance. The beauty is that it can work through many combinations in only a couple extra lines of code.\n",
    "\n",
    "Here's an example from the sklearn documentation:\n",
    "\n",
    "```python\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svr = svm.SVC()\n",
    "clf = grid_search.GridSearchCV(svr, parameters)\n",
    "clf.fit(iris.data, iris.target)\n",
    "```\n",
    "\n",
    "Let's break this down line by line.\n",
    "\n",
    "``` python\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "``` \n",
    "\n",
    "A dictionary of the parameters, and the possible values they may take. In this case, they're playing around with the kernel (possible choices are 'linear' and 'rbf'), and C (possible choices are 1 and 10).\n",
    "\n",
    "Then all the following combinations of values for (kernel, C) are automatically generated: ```[('rbf', 1), ('rbf', 10), ('linear', 1), ('linear', 10)]```. Each is used to train an SVM, and the performance is then assessed using cross-validation.\n",
    "\n",
    "```python\n",
    "svr = svm.SVC()\n",
    "``` \n",
    "\n",
    "This looks kind of like creating a classifier, just like we've been doing since the first lesson. But note that the \"clf\" isn't made until the next line--this is just saying what kind of algorithm to use. Another way to think about this is that the \"classifier\" isn't just the algorithm in this case, it's algorithm plus parameter values. Note that there's no monkeying \n",
    "around with the kernel or C; all that is handled in the next line.\n",
    "\n",
    "```python\n",
    "clf = grid_search.GridSearchCV(svr, parameters)\n",
    "``` \n",
    "\n",
    "This is where the first bit of magic happens; the classifier is being created. We pass the algorithm (svr) and the dictionary of parameters to try (parameters) and it generates a grid of parameter combinations to try.\n",
    "\n",
    "```python\n",
    "clf.fit(iris.data, iris.target)\n",
    "``` \n",
    "\n",
    "And the second bit of magic. The fit function now tries all the parameter combinations, and returns a fitted classifier that's automatically tuned to the optimal parameter combination. You can now access the parameter values via *clf.bestparams*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "#features_train = features_train[:len(features_train)/100] \n",
    "#labels_train = labels_train[:len(labels_train)/100]\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = preprocess() # full training set\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[10, 100, 1000, 10000]}\n",
    "svr = svm.SVC()\n",
    "clf = GridSearchCV(svr, parameters)\n",
    "\n",
    "\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "labels = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################################################\n",
    "### YOUR CODE HERE\n",
    "###############################################################\n",
    "\n",
    "### import the relevant code and make your train/test split\n",
    "### name the output datasets features_train, features_test,\n",
    "### labels_train, and labels_test\n",
    "\n",
    "### set the random_state to 0 and the test_size to 0.4 so\n",
    "### we can exactly check your result\n",
    "\n",
    "from sklearn import cross_validation\n",
    "\n",
    "iris.data.shape, iris.target.shape\n",
    "\n",
    "### We can now quickly sample a training set while holding out 40% of the data for testing \n",
    "### (evaluating) our classifier:\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(iris.data, \n",
    "                                iris.target, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90, 4), (90,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape, labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60, 4), (60,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test.shape, labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966666666667\n"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "\n",
    "clf = SVC(kernel=\"linear\", C=1.)\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "print clf.score(features_test, labels_test)\n",
    "\n",
    "\n",
    "##############################################################\n",
    "def submitAcc():\n",
    "    return clf.score(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "t0 = time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
