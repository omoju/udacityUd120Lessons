{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import sys\n",
    "import matplotlib as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "numpy.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataPath = '/Users/omojumiller/mycode/MachineLearningNanoDegree/IntroToMachineLearning/'\n",
    "sys.path.append(dataPath+'tools/')\n",
    "sys.path.append(dataPath+'final_project/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(dataPath+'final_project/final_project_dataset.pkl', \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- get email of author\n",
    "- compare to list of known persons of interest\n",
    "- return boolean if author is person of interest\n",
    "- aggregate count over all emails to person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "data_point = data_dict['METTS MARK']\n",
    "frac = data_point[\"from_poi_to_this_person\"] / data_point[\"to_messages\"]\n",
    "print frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeFraction( poi_messages, all_messages ):\n",
    "    \"\"\" given a number messages to/from POI (numerator) \n",
    "        and number of all messages to/from a person (denominator),\n",
    "        return the fraction of messages to/from that person\n",
    "        that are from/to a POI\n",
    "        \n",
    "   \"\"\"\n",
    "    ### you fill in this code, so that it returns either\n",
    "    ###     the fraction of all messages to this person that come from POIs\n",
    "    ###     or\n",
    "    ###     the fraction of all messages from this person that are sent to POIs\n",
    "    ### the same code can be used to compute either quantity\n",
    "\n",
    "    ### beware of \"NaN\" when there is no known email address (and so\n",
    "    ### no filled email features), and integer division!\n",
    "    ### in case of poi_messages or all_messages having \"NaN\" value, return 0.\n",
    "    \n",
    "    fraction = 0\n",
    "    \n",
    "    if poi_messages != 'NaN':\n",
    "        fraction = float(poi_messages) / float(all_messages)\n",
    "    \n",
    "\n",
    "\n",
    "    return fraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "  \n",
    "submit_dict = {}\n",
    "for name in data_dict:\n",
    "\n",
    "    data_point = data_dict[name]\n",
    "\n",
    "    from_poi_to_this_person = data_point[\"from_poi_to_this_person\"]\n",
    "    to_messages = data_point[\"to_messages\"]\n",
    "    fraction_from_poi = computeFraction( from_poi_to_this_person, to_messages )\n",
    "    #print fraction_from_poi\n",
    "    print'{:5}{:35}{:.2f}'.format('FROM ', name, fraction_from_poi)\n",
    "    data_point[\"fraction_from_poi\"] = fraction_from_poi\n",
    "\n",
    "\n",
    "    from_this_person_to_poi = data_point[\"from_this_person_to_poi\"]\n",
    "    from_messages = data_point[\"from_messages\"]\n",
    "    fraction_to_poi = computeFraction( from_this_person_to_poi, from_messages )\n",
    "    #print fraction_to_poi\n",
    "    print'{:5}{:35}{:.2f}'.format('TO: ', name, fraction_to_poi)\n",
    "    submit_dict[name]={\"from_poi_to_this_person\":fraction_from_poi,\n",
    "                       \"from_this_person_to_poi\":fraction_to_poi}\n",
    "    data_point[\"fraction_to_poi\"] = fraction_to_poi\n",
    "    \n",
    "    \n",
    "#####################\n",
    "\n",
    "def submitDict():\n",
    "    return submit_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beware of BUGS!!!\n",
    "\n",
    "When Katie was working on the Enron POI identifier, she engineered a feature that identified when a given person was on the same email as a POI. So for example, if Ken Lay and Katie Malone are both recipients of the same email message, then Katie Malone should have her \"shared receipt\" feature incremented. If she shares lots of emails with POIs, maybe she's a POI herself.\n",
    "\n",
    "Here's the problem: there was a subtle bug, that Ken Lay's \"shared receipt\" counter would also be incremented when this happens. And of course, then Ken Lay always shares receipt with a POI, because he is a POI. So the \"shared receipt\" feature became extremely powerful in finding POIs, because it effectively was encoding the label for each person as a feature.\n",
    "\n",
    "We found this first by being suspicious of a classifier that was always returning 100% accuracy. Then we removed features one at a time, and found that this feature was driving all the performance. Then, digging back through the feature code, we found the bug outlined above. We changed the code so that a person's \"shared receipt\" feature was only incremented if there was a different POI who received the email, reran the code, and tried again. The accuracy dropped to a more reasonable level.\n",
    "\n",
    "We take a couple of lessons from this:\n",
    "- Anyone can make mistakes--be skeptical of your results!\n",
    "- 100% accuracy should generally make you suspicious. Extraordinary claims require extraordinary proof.\n",
    "- If there's a feature that tracks your labels a little too closely, it's very likely a bug!\n",
    "- If you're sure it's not a bug, you probably don't need machine learning--you can just use that feature alone to assign labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Mini Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.append(dataPath+'text_learning/')\n",
    "\n",
    "words_file = \"your_word_data.pkl\" \n",
    "authors_file = \"your_email_authors.pkl\"\n",
    "word_data = pickle.load( open(words_file, \"r\"))\n",
    "authors = pickle.load( open(authors_file, \"r\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### test_size is the percentage of events assigned to the test set (the\n",
    "### remainder go into training)\n",
    "### feature matrices changed to dense representations for compatibility with\n",
    "### classifier functions in versions 0.15.2 and earlier\n",
    "\n",
    "from sklearn import cross_validation\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(word_data, \n",
    "                                                                            authors, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\n",
    "features_train = vectorizer.fit_transform(features_train)\n",
    "features_test  = vectorizer.transform(features_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### a classic way to overfit is to use a small number\n",
    "### of data points and a large number of features;\n",
    "### train on only 150 events to put ourselves in this regime\n",
    "\n",
    "features_train = features_train[:150].toarray()\n",
    "labels_train   = labels_train[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accurancy: 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "print\"{}{:.2f}\".format(\"Classifier accurancy: \", clf.score(features_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19671:0.074950\n",
      "21245:0.026316\n",
      "33201:0.134028\n",
      "33614:0.764706\n"
     ]
    }
   ],
   "source": [
    "featuresImportance =  clf.feature_importances_\n",
    "featuresSortedByScore = []\n",
    "\n",
    "for feature in range(len(featuresImportance)):\n",
    "    if featuresImportance[feature] > 0.0:\n",
    "        print \"{:d}:{:f}\".format(feature, featuresImportance[feature])\n",
    "        featuresSortedByScore.append([feature, featuresImportance[feature]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fyi\n",
      "home\n",
      "smith\n",
      "sshacklensf\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(featuresSortedByScore)):\n",
    "    print vectorizer.get_feature_names()[featuresSortedByScore[i][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
