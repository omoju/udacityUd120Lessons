{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of all the emails from Sara are in the `from_sara` list likewise for emails from Chris (`from_chris`).\n",
    "The actual documents are in the Enron email dataset, which you downloaded/unpacked. The data is stored in lists and packed away in pickle files at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from_sara  = open('../text_learning/from_sara.txt', \"r\")\n",
    "from_chris = open('../text_learning/from_chris.txt', \"r\")\n",
    "\n",
    "from_data = []\n",
    "word_data = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import string\n",
    "\n",
    "filePath = '/Users/omojumiller/mycode/hiphopathy/HipHopDataExploration/JayZ/'\n",
    "\n",
    "f = open(filePath+\"JayZ_American Gangster_American Gangster.txt\", \"r\")\n",
    "f.seek(0)  ### go back to beginning of file (annoying)\n",
    "all_text = f.read()\n",
    "\n",
    "content = all_text.split(\"X-FileName:\")\n",
    "words = \"\"\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "text_string = content\n",
    "for sentence in text_string:\n",
    "    words = sentence.split()\n",
    "    \n",
    "stemmed_words = [stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'm from the 80's, home of the heroine, error of the hustlers, uh the world is my custi new rich porter the way i flip quarter front on all these other rap artists, but me momma was a mink wearer, papa ran number so it plain to see, where my whole plan come from american dream, i'm live the life still the way i shine is like a zillion dollar light bill still i'm grinding, armi jacket line 40 below timb on, get my m on my best friend gone, i seen bad day still find song that i hear him on get my mari j. blige reminisc on i hear his voic in my mind, like, nigga live on so i get on that fli shit i been on spin on corner in enzo with rim on but for info, puffin on endo-nesia give me amnesia i eas up, that right, i'm high nigga i want the sky, the world when i'm done i'm give it to my son let em live it up, split it up, switch it up, six kit it up, man i did it up, done the rest of my belong belong in the hall of fame, a list of hit next to all my name i came, if the sky should fall and it all goe tomorrow, and they foreclos on the hous and auction off all my car don't cri for me argentina, i mob the beamer took trip abroad, got mob in sardina in ibiza i had pizza in the club ladi know i'm that guy, they wanna piec of my love now they wanna ya boy like mike in his prime billi jean the goddamn boy ain't mine and the roc break up, had the peopl lose hope can't lie they had muhammad hovi on the rope now i'm back in the go mode, back in the go-go throw the diamond up, rep the logo rose gold rose flow, i'm okay though what don't kill me make stronger than befor so here we go and i'm not domino when it all fall down, i'm like kany jaw i might break but i don't fold, till i hold the sky in my hand yeah that my goal and then i bid you freddi adu prodig child, y'all not readi for the futur then i disappear in the bermuda triangl my name will be view such here to the man that refus to give up i want the sky nigga, chuuuuuuch\n",
      "\n",
      "\n",
      "I'm from the 80's, Home of the heroine, Error of the hustlers, uh The world is my custy New rich porter The way I flip quarters Front on all these other rap artists, but me Momma was a mink wearer, Papa ran numbers So it's plain to see, where my whole plan come from American dream, I'm living the life still The way I shine is like a zillion dollar light bill Still I'm grinding, army jacket lining 40 below timbs on, getting my M's on My best friends gone, I seen bad days Still find songs that I hear him on Getting my Mary J. Blige Reminisce on I hear his voice in my mind, like, nigga live on So I get on that fly shit I been on Spin on corners in enzo with rims on But for info, puffin on Endo-Nesia Give me amnesia I ease up, that right, I'm high nigga I want the sky, The world when I'm done I'm give it to my sons Let 'em live it up, split it up, switch it up, Sixes kit it up, man I did it up, done The rest of my belongings belong in the hall of fame, a list of hits next to all my names I came, if the sky should fall And it all goes tomorrow, and they foreclose on the house and auction off all my cars Don't cry for me Argentina, I mobbed the beamer Took trips abroad, got mobbed in Sardina In Ibiza I had pizza in the club Ladies know I'm that guy, they wanna piece of my love Now they wanna ya boy like Mike in his prime Billie Jean the goddamn boy ain't mine And the Roc break up, had the people losing hope Can't lie they had Muhammad Hovi on the ropes Now I'm back in the go mode, back in the go-go's Throwing the diamond up, repping the logo Rose gold rose flow, I'm okay though What Don't kill me makes stronger than before so Here we go and I'm not domino When it all falls down, I'm like Kanye's jaw I might break but I don't fold, till I hold the sky in my hand Yeah that's my goal And then I bid you Freddy Adu Prodigal Child, y'all not ready for the future Then I disappear in the Bermuda Triangle My name will be viewed such Here's to the man that refused to give up I want the sky nigga, Chuuuuuuch\n"
     ]
    }
   ],
   "source": [
    "s = ' ';\n",
    "print s.join( stemmed_words )\n",
    "print '\\n\\n', s.join( words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseOutText(f):\n",
    "    \"\"\" given an opened email file f, parse out all text below the\n",
    "        metadata block at the top\n",
    "        \n",
    "        example use case:\n",
    "        f = open(\"email_file_name.txt\", \"r\")\n",
    "        text = parseOutText(f)\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    \n",
    "    f.seek(0)  ### go back to beginning of file (annoying)\n",
    "    all_text = f.read()\n",
    "\n",
    "    ### split off metadata\n",
    "    content = all_text.split(\"X-FileName:\")\n",
    "    words = \"\"\n",
    "    if len(content) > 1:\n",
    "        ### remove punctuation\n",
    "        text_string = content[1].translate(string.maketrans(\"\", \"\"), string.punctuation)\n",
    "\n",
    "        ### split the text string into individual words, stem each word,\n",
    "        ### and append the stemmed word to words (make sure there's a single\n",
    "        ### space between each stemmed word)\n",
    "        \n",
    "        words = ' '.join([stemmer.stem(word) for word in text_string.split()])\n",
    "        \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi everyon if you can read this messag your proper use parseouttext pleas proceed to the next part of the project\n"
     ]
    }
   ],
   "source": [
    "ff = open(\"../text_learning/test_email.txt\", \"r\")\n",
    "text = parseOutText(ff)\n",
    "print text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`temp_counter` is a way to speed up the development--there are thousands of emails from Sara and Chris, so running over all of them can take a long time. `temp_counter` helps you only look at the first 200 emails in the list so you can iterate your modifications quicker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emails processed\n"
     ]
    }
   ],
   "source": [
    "temp_counter = 1\n",
    "\n",
    "\n",
    "for name, from_person in [(\"sara\", from_sara), (\"chris\", from_chris)]:   \n",
    "    for path in from_person:\n",
    "        \n",
    "        ### only look at first 200 emails when developing\n",
    "        ### once everything is working, remove this line to run over full dataset\n",
    "        \n",
    "        #temp_counter += 1\n",
    "        \n",
    "        \n",
    "        if temp_counter:\n",
    "            path = os.path.join('..', path[:-1])\n",
    "            #print path\n",
    "            email = open(path, \"r\")\n",
    "\n",
    "            ### use parseOutText to extract the text from the opened email\n",
    "            text = parseOutText(email)\n",
    "\n",
    "            ### use str.replace() to remove any instances of the words\n",
    "            replaceWords = [\"sara\", \"shackleton\", \"chris\", \"germani\"]\n",
    "            for word in replaceWords:\n",
    "                text = text.replace(word, '')\n",
    "                \n",
    "\n",
    "            ### append the text to word_data\n",
    "            word_data.append(text)\n",
    "\n",
    "            ### append a 0 to from_data if email is from Sara, and 1 if email is from Chris\n",
    "            if name == \"sara\": \n",
    "                from_data.append(0)\n",
    "            else:\n",
    "                from_data.append(1)\n",
    "                \n",
    "\n",
    "            email.close()\n",
    "\n",
    "print \"emails processed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17578"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfIdf \n",
    "- Tf Term Frequency\n",
    "- Idf Inverse document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\",lowercase=True)\n",
    "bag_of_words = vectorizer.fit(word_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many different words are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38757"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is word number 34597 in your TfIdf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'stephaniethank'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[34597]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
